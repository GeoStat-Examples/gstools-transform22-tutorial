{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "# turn of warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Kriging geographical data\n",
    "\n",
    "In this example we are going to interpolate actual temperature data from\n",
    "the German weather service [DWD](https://www.dwd.de/EN).\n",
    "\n",
    "Data is retrieved utilizing the beautiful package\n",
    "[wetterdienst](https://github.com/earthobservations/wetterdienst),\n",
    "which serves as an API for the DWD data.\n",
    "\n",
    "For better visualization, we also download a simple shapefile of the German\n",
    "borderline with [cartopy](https://github.com/SciTools/cartopy).\n",
    "\n",
    "In order to keep the number of dependecies low, the calls of both functions\n",
    "shown beneath are commented out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gstools as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_borders_germany():\n",
    "    \"\"\"Download simple german shape file with cartopy.\"\"\"\n",
    "    import geopandas as gp  # 0.8.1\n",
    "    from cartopy.io import shapereader as shp_read  # version 0.18.0\n",
    "\n",
    "    shpfile = shp_read.natural_earth(\"50m\", \"cultural\", \"admin_0_countries\")\n",
    "    df = gp.read_file(shpfile)  # only use the simplest polygon\n",
    "    poly = df.loc[df[\"ADMIN\"] == \"Germany\"][\"geometry\"].values[0][0]\n",
    "    np.savetxt(\"de_borders.txt\", list(poly.exterior.coords))\n",
    "\n",
    "\n",
    "def get_dwd_temperature(date=\"2020-06-09 12:00:00\"):\n",
    "    \"\"\"Get air temperature from german weather stations from 9.6.20 12:00.\"\"\"\n",
    "    from wetterdienst.dwd import observations as obs  # version 0.13.0\n",
    "\n",
    "    settings = dict(\n",
    "        resolution=obs.DWDObservationResolution.HOURLY,\n",
    "        start_date=date,\n",
    "        end_date=date,\n",
    "    )\n",
    "    sites = obs.DWDObservationStations(\n",
    "        parameter_set=obs.DWDObservationParameterSet.TEMPERATURE_AIR,\n",
    "        period=obs.DWDObservationPeriod.RECENT,\n",
    "        **settings,\n",
    "    )\n",
    "    ids, lat, lon = sites.all().loc[:, [\"STATION_ID\", \"LAT\", \"LON\"]].values.T\n",
    "    observations = obs.DWDObservationData(\n",
    "        station_ids=ids,\n",
    "        parameters=obs.DWDObservationParameter.HOURLY.TEMPERATURE_AIR_200,\n",
    "        periods=obs.DWDObservationPeriod.RECENT,\n",
    "        **settings,\n",
    "    )\n",
    "    temp = observations.all().VALUE.values\n",
    "    sel = np.isfinite(temp)\n",
    "    # select only valid temperature data\n",
    "    ids, lat, lon, temp = ids.astype(float)[sel], lat[sel], lon[sel], temp[sel]\n",
    "    head = \"id, lat, lon, temp\"  # add a header to the file\n",
    "    np.savetxt(\"temp_obs.txt\", np.array([ids, lat, lon, temp]).T, header=head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to download the data again,\n",
    "uncomment the two following lines. We will simply load the resulting\n",
    "files to gain the border polygon and the observed temperature along with\n",
    "the station locations given by lat-lon values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# get_borders_germany()\n",
    "# get_dwd_temperature(date=\"2020-06-09 12:00:00\")\n",
    "\n",
    "border = np.loadtxt(\"de_borders.txt\")\n",
    "ids, lat, lon, temp = np.loadtxt(\"temp_obs.txt\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will estimate the variogram of our temperature data.\n",
    "As the maximal bin distance we choose 8 degrees, which corresponds to a\n",
    "chordal length of about 900 km.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bins = gs.standard_bins((lat, lon), max_dist=np.deg2rad(8), latlon=True)\n",
    "\n",
    "bin_c, vario = gs.vario_estimate((lat, lon), temp, bins, latlon=True)\n",
    "print(np.rad2deg(bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this estimated variogram to fit a model to it.\n",
    "Here we will use a `Spherical` model. We select the `latlon` option\n",
    "to use the *Yadrenko* variant of the model to gain a valid model for lat-lon\n",
    "coordinates and we rescale it to the earth-radius. Otherwise the length\n",
    "scale would be given in radians representing the great-circle distance.\n",
    "\n",
    "We deselect the nugget from fitting and plot the result afterwards.\n",
    "\n",
    "## Note\n",
    "You need to plot the Yadrenko variogram, since the standard variogram\n",
    "still holds the ordinary routine that is not respecting the great-circle\n",
    "distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = gs.Spherical(latlon=True, rescale=gs.EARTH_RADIUS)\n",
    "model.fit_variogram(bin_c, vario, nugget=False)\n",
    "ax = model.plot(\"vario_yadrenko\", x_max=max(bin_c))\n",
    "ax.scatter(bin_c, vario)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, we have a rather large correlation length of 600 km.\n",
    "\n",
    "Now we want to interpolate the data using `Universal` kriging.\n",
    "In order to tinker around with the data, we will use a north-south drift\n",
    "by assuming a linear correlation with the latitude.\n",
    "This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def north_south_drift(lat, lon):\n",
    "    return lat\n",
    "\n",
    "\n",
    "uk = gs.krige.Universal(\n",
    "    model=model,\n",
    "    cond_pos=(lat, lon),\n",
    "    cond_val=temp,\n",
    "    drift_functions=north_south_drift,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate the kriging field, by defining a lat-lon grid that covers\n",
    "the whole of Germany. The `Krige` class provides the option to only\n",
    "krige the mean field, so one can have a glimpse at the estimated drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# grid\n",
    "g_lat = np.arange(47, 56.1, 0.1)\n",
    "g_lon = np.arange(5, 16.1, 0.1)\n",
    "# set pos\n",
    "uk.set_pos((g_lat, g_lon), mesh_type=\"structured\")\n",
    "# get field and estimated mean drift\n",
    "field = uk(return_var=False, store=\"temp_field\")\n",
    "mean = uk(only_mean=True, store=\"mean_field\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. Now let's have a look at the generated field and the input\n",
    "data along with the estimated mean:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "levels = np.linspace(5, 23, 64)\n",
    "fig, ax = plt.subplots(1, 3, figsize=[10, 5], sharey=True)\n",
    "sca = ax[0].scatter(lon, lat, c=temp, vmin=5, vmax=23, cmap=\"coolwarm\")\n",
    "co1 = ax[1].contourf(g_lon, g_lat, uk[\"temp_field\"], levels, cmap=\"coolwarm\")\n",
    "co2 = ax[2].contourf(g_lon, g_lat, uk[\"mean_field\"], levels, cmap=\"coolwarm\")\n",
    "\n",
    "[ax[i].plot(border[:, 0], border[:, 1], color=\"k\") for i in range(3)]\n",
    "[ax[i].set_xlim([5, 16]) for i in range(3)]\n",
    "[ax[i].set_xlabel(\"Lon in deg\") for i in range(3)]\n",
    "ax[0].set_ylabel(\"Lat in deg\")\n",
    "\n",
    "ax[0].set_title(\"Temperature observations at 2m\\nfrom DWD (2020-06-09 12:00)\")\n",
    "ax[1].set_title(\"Interpolated temperature\\nwith North-South drift\")\n",
    "ax[2].set_title(\"Estimated mean drift\\nfrom Universal Kriging\")\n",
    "\n",
    "fmt = dict(orientation=\"horizontal\", shrink=0.5, fraction=0.1, pad=0.2)\n",
    "fig.colorbar(co2, ax=ax, **fmt).set_label(\"T in [Â°C]\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better impression of the estimated north-south drift, we'll take\n",
    "a look at a cross-section at a longitude of 10 degree:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(g_lat, uk[\"temp_field\"][:, 50], label=\"Interpolated temperature\")\n",
    "ax.plot(g_lat, uk[\"mean_field\"][:, 50], label=\"North-South mean drift\")\n",
    "ax.set_xlabel(\"Lat in deg\")\n",
    "ax.set_ylabel(\"T in [Â°C]\")\n",
    "ax.set_title(\"North-South cross-section at 10Â°\")\n",
    "ax.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretion of the results is now up to you! ;-)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
